{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.4.3+"}}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"# Tutorial (SOLUTIONS) 1: Numbers"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"It seems obvious that real numbers $\\mathbb{R}$ are a key element of computation. But there are some subtle aspects to numbers that it's worth thinking about. We think of numbers alnog a line like this:\n\n![Number line](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Real_number_line.svg/1000px-Real_number_line.svg.png)\n\nYou are told that \"almost all\" of the numbers on this line are irrational. That means if you throw a dart at the line you should never \"hit\" a rational number. The irrationals fill the entire line. \n\nBut there is a paradox:\n\n*No one has ever met a true irrational number in person. We hear a lot of name droping. People say things like, \"I know $\\pi$ and $e$.\" They are big celebrities in some circles. But no one's ever really seen them in their total infinity. Only fleeting glimpses as they run down the street and jump into a limo.*\n\nMy person view: Irrational numbers are a convinent fiction. They are \"defined\" as the completion of the rationals under limits of Cauchy sequences. What?\n\nSay you have a sequence of rationals (ie \"fractions\" or ratios of integers), $r_{0}, r_{1}, r_{2}, \\ldots, r_{n}, r_{n+1}, \\ldots$. And say you have a way of comparing the distance between any two numbers,\n\n$$ | r_{n} - r_{m} |. $$\n\nNow say that for any tiny number you pick, say 1/1,000,000,000, or 1/1,000,000,000,000, or $10^{-16}$. You can always find an $n$ and and $m$ where \n\n$$ | r_{n} - r_{m} |  < 10^{-16}.$$\n\nAnd if someone had said $10^{-\\mathrm{googolplex}}$, we would have been able to find an $n$ and $m$ for that too. \n\nWe call this kind of sequence of rational number a ***Cauchy sequence***. It looks like it's going somewhere. But at every step of the way, it's just a bunch of rational numbers. \n\nThe thing about these kinds of sequences is that there may not be a rational number at the end of it. The definition is to just make a bigger set of numbers that includes these limits and go on our way as if nothing was ever awkward."}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"***Here's an example of one such sequence.***"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"Take $r_{0} = 1$.  At every step of the sequence, define \n\n$$r_{n+1} = \\frac{r_{n}+2}{r_{n}+1}$$\n\nNothing but a bunch of rationals all the way... It's also possible to prove that the terms get closer and closer together. "}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"**LECTURE'S PERSONAL NOTE:** \n\nIt is my personal belief that a lot of students think of \"Take the limit as $n\\to \\infty$\" as very conceptually similar to \"plug in the vaule $n=\\infty$.\" At least my friends and I thought this way as students far into our education. There is good reason for this sometimes. I still do it when I'm in a hurry. And it works on paper sometimes. But this is the beauty of computers. They *will just not let you \"plug in $\\infty$\"*. OK, they do allow it sometimes. They sometimes have a number called `inf`. And you can use this productively sometimes. But you sure better know what you are doing! If you use `inf`, you also better get used to the idea of `nan`, which mean \"not a number\". See the examples below.\n\nComputers make you realise that everyting useful is finite. And the infinite is just the idea that you can keep doing something as long as you want. And maybe you can make a good guess where the result is going. But you'll *never* actually get to the end. "}
{"cell_type":"code","execution_count":1,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"0.0\ninf\n-inf\ninf\ninf\nnan\nnan\nnan\nnan\n"}],"source":"import numpy as np\nprint(1/np.inf)\nprint(1+np.inf)\nprint(1-np.inf)\nprint(np.inf*np.inf)\nprint(np.inf+np.inf)\nprint(np.inf/np.inf)\nprint(np.inf-np.inf)\nprint(1 + np.nan)\nprint(np.inf*np.nan)"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"`inf` can get into a calculation and things can still turn out ok. But used the wrong way, `inf` can turn to it's evil partner, `nan`. Anything `nan` touches turns to `nan`."}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"**BACK TO OUR REGULARLY SCHEDULED PROGRAM**"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"**TASK 0**: Analytically determine the limiting value of the recursive sequence $r_{n}$. This where the sequence doesn't change anymore; $r_{n+1} = r_{n}$. Practise writing your answer using Markdown in the space below."}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"**SOLUTION 0:** \n\nThe fixed-point value is defined by:\n\n$$r_{\\infty} = \\frac{r_{\\infty} + 2}{r_{\\infty}+1} $$\n\nor\n\n$$ r_{\\infty}(r_{\\infty}+1) \\ = \\ r_{\\infty} + 2$$\n\nor\n\n$$ r_{\\infty}^{2} \\ = \\ 2 $$\n\nor \n\n$$r_{\\infty} \\ = \\ \\pm \\sqrt{2}$$\n\nIf we start with positive values we remain positive. Therefore\n\n$$r_{\\infty} \\ = \\ \\sqrt{2}$$\n\nWe hope \n\n$$ \n\\lim_{n\\to \\infty} r_{n}^{2} \\ = \\ 2\n$$"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"**TASK 1**: Write a recursive function that generates the $n$th term in this sequence. Show that the terms get closer to eachother. "}
{"cell_type":"markdown","metadata":{},"source":"**SOLUTION 1:**"}
{"cell_type":"code","execution_count":2,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[],"source":"# Define function here\ndef r(n):\n    if n == 0: return 1\n    x = r(n-1) # only call r(n-1) once! \n    return (x+2)/(x+1)"}
{"cell_type":"code","execution_count":3,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"1\n1.5\n1.4\n4.440892098500626e-16\nSeems to work.\n"}],"source":"# Test function here\nprint(r(0))\nprint(r(1))\nprint(r(2))\nprint(r(100)**2 - 2)\nprint('Seems to work.')"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"Warning: you will have to reboot the Kernal if you type np.inf into your function. Why?"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"**TASK 2:** Can we find integers, $i_{n}$, such that \n\n$$ r_{n} = \\frac{i_{n} + i_{n-1}}{i_{n}} \\quad ?$$\n\nShow that the following sequence works \n\n$$ i_{n+1} = 2 i_{n} + i_{n-1}.$$\n\nfor some starting values, $i_{-1}$, and $i_{0}$. Find the starting values that make this work. \n\n\nDoes this sequence look similar to another (perhaps simpler) sequence you've seen in your education so far? There is a good reason for that. We'll learn more about why a little later."}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"**SOLUTION 2:**\n\nMath pro tip: If you want to see if two things are the same, then subtract them.\n\n$$ r_{n+1} - \\frac{r_{n}+2}{r_{n}+1} \\ = \\ \\frac{i_{n+1}+i_{n}}{i_{n+1}} -   \\frac{3 i_{n}+i_{n-1}}{2i_{n}+i_{n-1}} \\ = \\ i_{n}\\left(\\frac{1}{i_{n+1}} - \\frac{1}{2 i_{n} + i_{n-1}} \\right)$$\n\nThe left-hnad side is zero if $i_{n}=0$ for all $n$; which is not what we want. Or if\n\n$$i_{n+1} = 2 i_{n} + i_{n-1}\\quad \\mathrm{QED}.$$\n\nWe want \n\n$$r_{0} \\ = \\  1 \\ = \\ \\frac{i_{0}+i_{-1}}{i_{0}} \\ = \\ 1 + \\frac{i_{-1}}{i_{0}} $$\n\nThis works as long as $i_{-1} \\ = \\ 0$, and $i_{0} \\ne 0$. We can pick $i_{0}$ to be anything we want otherwise. A good values is $i_{0} = 1$. "}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"**TASK 3:** write a recursive function that generates the sequence $i_{n}$. Take the ratio in TASK 2 and show the result is the same as the function output in TASK 1."}
{"cell_type":"markdown","metadata":{},"source":"***SOLUTION 3:*** Here are two way you could do the same thing:"}
{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"deletable":true,"editable":true,"trusted":true},"outputs":[],"source":"def i(n):\n    if n <  0: return 0\n    if n == 0: return 1\n    return 2*i(n-1) + i(n-2)\n\ndef matrix_power(matrix,n):\n        if n == 0: return np.array([[1,0],[0,1]])\n        return matrix.dot(matrix_power(matrix,n-1))\n\ndef i_matrix(n):\n    \n    if n <  0: return 0\n    if n == 0: return 1\n\n    Q = matrix_power(np.array([[2,1],[1,0]]),n)\n\n    return Q[0,0]"}
{"cell_type":"code","execution_count":5,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"True\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n"}],"source":"for n in range(10): print( i(n) == i_matrix(n))"}
{"cell_type":"markdown","metadata":{},"source":"One of these function is a lot faster than the other.  Let's quantify this."}
{"cell_type":"code","execution_count":6,"metadata":{"collapsed":true,"trusted":true},"outputs":[],"source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nimport time \n\ndef measure_time(fun,arg,nreps=1):\n    t = time.time()\n    for k in range(nreps):\n        fun(arg)\n    t -= time.time()\n    t /= -nreps\n    return t"}
{"cell_type":"code","execution_count":7,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7f177394a780>]"},"execution_count":7,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"smc-blob::b0c48669-613b-435d-bea1-672fc27d9a84","text/plain":"<matplotlib.figure.Figure at 0x7f177394a0b8>"},"metadata":{},"output_type":"display_data"}],"source":"nmax=30\ntime0, time1 = np.zeros(nmax), np.zeros(nmax)\nfor n in range(nmax):\n    time0[n] = measure_time(i,n)\n    time1[n] = measure_time(i_matrix,n,nreps=300)\n\nplt.semilogy(time0,color='red')\nplt.semilogy(time1,color='green')"}
{"cell_type":"markdown","metadata":{},"source":"It would be possible to speed this up even more with a `fast_matrix_power` function."}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"## The decimal system"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"When you look at the output of your $r_{n}$ function, you'll notice that you get the answer in perfectly sensible decimal numbers. This is just one convienent way of representing sequences of rational numbers with higher and higher precision."}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"$$x = \\lim_{D\\to \\infty}\\ \\sum_{i=-D}^{D} d_i 10^{i},$$\n\nwith \n\n$$d_{i} \\in \\{0,1,2,3,4,5,6,7,8,9\\}.$$"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"Notice that I took the limit as the range of terms $[-D,+D]$ goes to $\\infty$. This is becuase we can't really ever get everyting in one place. \n\nThe Decimal system is just one more way of looking at sequences of rational numbers. And we know there are some drawbacks to this also.  Numbers like $1/3$ have decimal representations that go on repeting forever. If you want to represent $1/3$ exactly you need to use a base-3 system. \n\nBut we still need to calculate with numbers like $pi$ and $1/3$. But we cannot fit them in our finite computers. This leads to one of the two main sources of error in computations. \n"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"## The binary system \nVirtually every computer uses binary to store numbers. A binary number system uses only two values, canonically 0 and 1, in each digit, as opposed to the ten we use in decimal. Very briefly, here is a short table showing the conversion of the first ten integers from decimal to binary:\n\n|Decimal|Binary|\n|-------|------|\n|00|0000|\n|01|0001|\n|02|0010|\n|03|0011|\n|04|0100|\n|05|0101|\n|06|0110|\n|07|0111|\n|08|1000|\n|09|1001|\n|10|1010|\n\nEach digit of the binary number is called a \"bit\" (\"binary digit\"). Thus, the bit is the smallest unit of computer memory. One \"byte\" is 8 bits. \n\nJust as an arbitrary number can be written in decimal as an arbitrary number can be written in binary as \n\n$$x = \\lim_{B\\to\\infty}\\  \\sum_{i=-B}^{B} b_i 2^{i},$$\n\nNow\n\n$$b_{i} \\in \\{0,1\\}.$$\n"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"Decimal and binary system (and all other integer-base systems) have the nice property that they are (almost) \"unique\". That is if any two numbers have the same binary or decimal expansion, then they are the same number.\n\nThere is one important exception to this. In decimal, the number \n\n$$u =  0.9999999999999999999\\ (\\mathrm{repeting})$$\n\nis not it's own number. This number is equal to $u=1$. In binary the same is true for\n\n$$u = 0.11111111111111111 \\ (\\mathrm{repeting}).$$\n\nThere are a lot of clever ways to prove these. We saw a hint about this in Lecture 01.  "}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"**TASK 04:** Use the following (finite) geometric series formula to prove $u=1$ from above:\n\n$$(q-1) \\sum_{i=1}^{n} q^{-i} \\ = \\ 1 - q^{-n}$$\n"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"**SOLUTION 4:**\n\nAssume $q=10$ for base-10:\n\nThen \n\n$$0.9000 = 9 \\times 10^{-1}$$\n\n$$0.9900 = 9 \\left( 10^{-1} + 10^{-2}\\right)$$\n\n$$0.9990 = 9 \\left( 10^{-1} + 10^{-2} + 10^{-3}\\right)$$\n\n$$0.9999 = 9 \\left( 10^{-1} + 10^{-2} + 10^{-3} + 10^{-4}\\right)$$\n\nAnd so on. For $n$ 9s:\n\n$$ 0.9....9000 \\ = \\  9 \\sum_{i=1}^{n} 10^{-i} \\ = \\ 1 - 10^{-n} $$\n\n$$ 0.9999999999999999999\\ (\\mathrm{repeting}) \\ = \\ \\lim_{n\\to \\infty} ( 1 - 10^{-n}) \\ = \\ 1$$.\n\nThe same is true in base-2."}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"**Experimenting with binary:**\n\n`numpy` provides a function (`np.binary_repr()`) to convert *integers* into their binary represenation. Let's practice a bit by using it. Try changing $n$ below. Try a bunch of numbers to get a feel for how binary works. You might try putting `np.binary_repr()` into a loop."}
{"cell_type":"code","execution_count":8,"metadata":{"collapsed":true,"deletable":true,"editable":true,"trusted":true},"outputs":[],"source":"import numpy as np"}
{"cell_type":"code","execution_count":9,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[{"data":{"text/plain":"'101010'"},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":"n = 42\n\nnp.binary_repr(n)"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"**TASK 05:** Insert a new cell below. See what happens when you try to give a floating point number (e.g. 43.2) to `np.binary_repr()`. Read the output carefully. "}
{"cell_type":"markdown","metadata":{},"source":"**SOLUTION 5:**"}
{"cell_type":"code","execution_count":10,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"It aint gonna like it:\n"},{"ename":"TypeError","evalue":"'float' object cannot be interpreted as an integer","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-88f26e187314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'It aint gonna like it:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m43.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.4/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mbinary_repr\u001b[0;34m(num, width)\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2272\u001b[0;31m         \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2273\u001b[0m         \u001b[0mbinwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2274\u001b[0m         outwidth = (binwidth if width is None\n","\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"]}],"source":"print('It aint gonna like it:')\nnp.binary_repr(43.2) "}
{"cell_type":"markdown","metadata":{},"source":"** EVERYTHING FROM HERE ON IS JUST EXPERIMENTING. THERE ARE NO 'SOLUTIONS'. BUT YOU ARE GOING TO WANT TO GET AN UNDERSTANDING OF BINARY. IT MAY SHOW UP LATER. **"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"## Floating Point Numbers\n\nThroughout this class, we will need to work with computer representations of real numbers: we'll be adding, subtracting, dividing, and multiplying them in order to solve complex problems regarding the world. As an example, The observable physical universe covers length scales from the size of the proton, $l_p \\sim 10^{-14}\\ \\mathrm{m}$,\\* to the size of the observable universe, $L_u \\sim 10^{27}\\ \\mathrm{m}$. Taking the ratio of $L_u/l_p \\simeq 10^{41}$, we see there is a factor of $10^{41}$ between the smallest and largest length scales. \n\nIn order to cover quantities over a large \"dynamic range\", we typically use scientific notation in our paper-and-pencil work, and computers do very much the same thing.  The only tricky part is that the number, which we like to represent in decmial form, is stored in binary. \n\nLet's analyze scientific notation. Take an interesing small number. For example, the mass of an electron $ \\mu = 9.10938356 \\times 10^{-31} \\mathrm{kg}$. \n\nWe can write this schematically as \n\n$$ \\mu = (-1)^s\\ m\\ \\times 10^e,$$\n\nwhere $s=0$ is called the *sign*, $m= 9.10938356$ the *mantissa* (or significant), and $e=-31$ the *exponent*. \n\nOf course, the computer stores the number $\\mu$ in binary, so it must be converted. We'll use the notation $N_{10}$ to mean a number $N$ in base 10, and $N_{2}$ to mean a number in base 2. For example $10_{10} = 1010_{2}$. \n\n## IEEE 754\n\nhttps://en.wikipedia.org/wiki/IEEE_floating_point\n\nThere are many ways of storing floating point numbers on a computer; we will only describe one: IEEE 754. This is the most widely used standard for representing these numbers. An IEEE 754 number is represented in the following way:\n\n$$ x = (-1)^s\\ 1.f\\ \\times 2^{e-B},$$\n\nwhere $s$ is the sign, $f$ is the *fractional part* of the mantissa (note that there is 1 in front), $e$ is the exponent of the number you want to represent, and $B$ is called the *bias*. Note that the total exponent stored in memory $e$  has no sign bit and is thus **always positive**. This explains the need for the bias: if we want to represent actual exponents $p = e -B < 0$, $B>0$. A floating point number standard that can't hold the mass of an electron is not very useful to scientists. The bias $B = 127$ for single precision, and \n\nIEEE 754 defines two different kinds of floating point numbers: single and double precision. Single precision floating point numbers are called `float`s and take up 32 bits of memory, and double precision is called `double` and take up 64 bits of memory. \n\n**Unfortunately, python doesn't respect this naming convention**, chosing instead to use `float` to mean a 64-bit number, and `float32` to mean a 32-bit number. This is only mildly annoying in practice, since you'll probably never need a 32-bit float in this class. Computer 15 years ago all used 32-bit number as defaults. They pretty much all switched over at some point to using 64-bit defaults. Maybe on day, this will change to 128-bit. But for now that is also an option that will slow down computations. \n\nWe'll use 32-bit single precision as our example here, even though you will almost always work in double precision. A 32 bit `float` uses 1 bit to hold the sign $s$, 8 bits to hold the exponent $e$, and the remaining 23 bits to hold the mantissa. Let's consider the exponent first. With 8 bits, the largest value that can be held is with all 8 digits set to 1, 11111111:"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"Convert a binary digit written as a string (that is, in quotes) prefaced with '0b' to decimal integers"}
{"cell_type":"code","execution_count":11,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[{"data":{"text/plain":"255"},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":"int('0b11111111',base=2) "}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"The smallest value is 00000000:"}
{"cell_type":"code","execution_count":12,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[{"data":{"text/plain":"0"},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":"int('0b00000000',base=2) "}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"So, $0 \\leq e \\leq 255$. In IEEE 754, $e=0$ and $e=255$ are special, so normal numbers are restricted to $0 \\lt e \\lt 255$. \n\nThe fractional part of the mantissa is 23 bits wide, plus the 1 we assue leads the mantissa, for a total of 24 digits. So the largest possible mantissa is (remember, this is really a binary *fraction*: 1.11111111111111111111111)"}
{"cell_type":"code","execution_count":13,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[{"data":{"text/plain":"1.9999998807907104"},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":"int('0b111111111111111111111111',base=2)*2**-23"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"So, putting these together, the largest digit we can store is "}
{"cell_type":"code","execution_count":14,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"3.402823466385289e+38\n"}],"source":"m = int('0b111111111111111111111111',base=2)*2**-23\nbias = 127\nexp = 2**(254-bias)\n\nprint(\"{:20.15e}\".format(m*exp))"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"As mentioned above, the case $e = 0$ is a special one. In this case, the 23 mantissa bits represent the entire mantissa, and the leading digit is zero (instead of one, as is usual). Also, the total stored exponent will be -126. So, the smallest number is thus"}
{"cell_type":"code","execution_count":15,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"1.401298464324817e-45\n"}],"source":"m = int('0b000000000000000000000001',base=2)*2**-23\nexp = 2**(-126)\n\nprint(\"{:20.15e}\".format(m*exp))"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"### Simfloat\n\nWe're going to use the simfloat package to simulate floating point numbers. This allows us to look easily at what the binary representation is.\n\n**Note: This package might be buggy!** If you have any problems, let me know. Don't worry, we're not going to be using it for any marked assignments. It's just for fun."}
{"cell_type":"code","execution_count":16,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[],"source":"import simfloat as sf"}
{"cell_type":"code","execution_count":17,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[],"source":"context = sf.single # this is a predefined single-precision floating point simulation"}
{"cell_type":"markdown","metadata":{"deletable":true,"editable":true},"source":"Modify the cells below to get a feel for binary represenations of common decimal digits. Note when the mantissa becomes totally full, and when it's not. Think about what that sometimes means in decimal (e.g. think about 1/3!), and what implications that has for computation on binary computers. \n\nIn particular, try 1, 0.1, 0.5, and 1/3."}
{"cell_type":"code","execution_count":18,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"0 10000010 01100000000000000000000\n"}],"source":"x = context(11)\n\nprint(x)"}
{"cell_type":"code","execution_count":19,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[{"data":{"text/plain":"1.5648180798146291e-34"},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":"1.625*2**-113"}
{"cell_type":"code","execution_count":20,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"0 00001110 10100000000000000000000\n"}],"source":"x = context(1.5648180798146291e-34)\nprint(x)"}
{"cell_type":"code","execution_count":21,"metadata":{"collapsed":false,"deletable":true,"editable":true,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"1 01111111 00000000000000000000000\n"}],"source":"x = context(-1)\nprint(x)"}
{"cell_type":"code","execution_count":22,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"0 11111111 11111111111111111111111\n"}],"source":"x = context(np.nan)\nprint(x)"}
{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"trusted":true},"outputs":[],"source":""}